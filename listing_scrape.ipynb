{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Import all libraries and scraping one\n",
    "2. Import all libraries we used for SQL Lite\n",
    "3. Query our database and retrieve all entries\n",
    "4. For each entry we'll scrape the listing date, listing price from URL that's in database\n",
    "5. Update database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('sanfrancisco.db')\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: splinter in /anaconda3/lib/python3.7/site-packages (0.10.0)\n",
      "Requirement already satisfied: selenium>=3.141.0 in /anaconda3/lib/python3.7/site-packages (from splinter) (3.141.0)\n",
      "Requirement already satisfied: urllib3 in /anaconda3/lib/python3.7/site-packages (from selenium>=3.141.0->splinter) (1.23)\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "/usr/local/bin/chromedriver\n"
     ]
    }
   ],
   "source": [
    "!pip install splinter\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "!which chromedriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path' : '/usr/local/bin/chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(url):\n",
    "\n",
    "#     url = 'https://www.redfin.com/city/17151/CA/San-Francisco/filter/property-type=house,min-beds=3,min-baths=2,include=sold-3mo'\n",
    "    browser.visit(url)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    html=browser.html\n",
    "    soup=BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    \n",
    "       headers = {'User-Agent': \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/601.3.9 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9\"}\n",
    "       response = requests.get(url, headers=headers)\n",
    "\n",
    "\n",
    "\n",
    "    soup = BeautifulSoup(response.text,'html.parser')\n",
    "    results = soup.find_all('span', class_=\"entryItemContent\")\n",
    "    \n",
    "\n",
    "    original_price=None\n",
    "    for result in results:\n",
    "        try:\n",
    "            index = result.text.find(\"Original Price: \")\n",
    "            if index != -1:\n",
    "                price=result.text[16:len(result.text)]\n",
    "                print(price)\n",
    "                original_price=int(float(price.replace(',','').replace('$','')))\n",
    "                print(\"Original Price: \" + (str(original_price)))\n",
    "                  \n",
    "                break\n",
    "      \n",
    "        except AttributeError as e:\n",
    "            print(e)\n",
    "            \n",
    "    print(original_price)\n",
    "    \n",
    "    listing_date=None\n",
    "    for result in results:\n",
    "        try:\n",
    "            search_string = \"On Market Date: \"\n",
    "            index = result.text.find(search_string)\n",
    "            if index != -1:\n",
    "                listing_date=result.text[len(search_string):len(result.text)]\n",
    "                print(\"Listing Date: \" + (str(listing_date)))\n",
    "                listing_date=int(datetime.datetime.strptime(listing_date,\"%A, %B %d, %Y\").strftime(\"%s\"))\n",
    "\n",
    "                break\n",
    "\n",
    "        except AttributeError as e:\n",
    "                print(e)\n",
    "                print(listing_date)\n",
    "    return original_price, listing_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = conn.cursor()\n",
    "c.execute(\"SELECT Address, URL FROM Address WHERE Original_Price IS Null\")\n",
    "\n",
    "rows = c.fetchall()\n",
    "iteration = 1\n",
    "\n",
    "missing_data = [\n",
    "    \"2924 Rivera St\",\n",
    "    \"1230 5th Ave\",\n",
    "    \"87 Melrose Ave\",\n",
    "    \"2211 44th Ave\",\n",
    "    \"860 De Haro St\",\n",
    "    \"701 Quintara St\",\n",
    "    \"345 Holly Park Cir\",\n",
    "    \"160 Anderson St\",\n",
    "    \"156 Midcrest Way\",\n",
    "    \"51 Somerset St\",\n",
    "    \"2038 20th Ave\",\n",
    "    \"1727 31st Ave\",\n",
    "    \"2271 40th Ave\",\n",
    "    \"525 Holloway Ave\",\n",
    "    \"34 Wanda St\"\n",
    "]\n",
    "\n",
    "for row in rows:\n",
    "    address = row[0]\n",
    "    \n",
    "    # Missing data on web page\n",
    "    if address in missing_data:\n",
    "        continue\n",
    "    \n",
    "    url = row[1]\n",
    "    print(address)\n",
    "    print(url)\n",
    "    print(row)\n",
    "    \n",
    "    redfin=scrape(url)\n",
    "    original_price = redfin[0]\n",
    "    listing_date = redfin[1]\n",
    "    \n",
    "    c.execute('''UPDATE Address SET Original_Price = ? , Listing_date = ? WHERE Address = ?\n",
    "            ''', (original_price,listing_date,address))\n",
    "    conn.commit()\n",
    "\n",
    "    print(\"Completed \" + str(iteration) + \" of \" + str(len(rows)) + \"...\")\n",
    "    iteration += 1\n",
    "    \n",
    "    if iteration > 10:\n",
    "        print(\"stopping iterations...\")\n",
    "        break\n",
    "    \n",
    "    time.sleep(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse the string to add the Listing Price/Sold Price\n",
    "# Talk about the bot detection of Redfin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
